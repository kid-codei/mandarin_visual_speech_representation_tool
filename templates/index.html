<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Mandarin Visual Speech Tool</title>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <style>
    body {
      font-family: sans-serif;
      padding: 20px;
    }
    #pitch-plot {
      width: 100%;
      height: 400px;
      margin-top: 40px;
    }
    #text-alignment {
      margin-top: 20px;
      font-size: 1.2em;
    }
    #english-sentence {
      margin-top: 10px;
      font-size: 1em;
      color: #555;
    }
    #recordingIndicator {
      color: red;
      font-weight: bold;
      margin: 10px 0;
    }
    button {
      margin-right: 10px;
    }
  </style>
</head>
<body>
  <h1>Mandarin Visual Speech Tool</h1>

  <!-- dropdown to choose a sentence; options are populated dynamically from the backend -->
  <label for="fileSelector">Choose sentence:</label>
  <select id="fileSelector"></select>

  <label for="scriptChoice" style="margin-left: 20px;">Display:</label>
  <select id="scriptChoice">
    <option value="pinyin">Pinyin Only</option>
    <option value="traditional">Traditional</option>
    <option value="simplified">Simplified</option>
    <option value="both_trad">Traditional + Pinyin</option>
    <option value="both_simp">Simplified + Pinyin</option>
  </select>

  <div id="english-sentence"></div>
  <div id="text-alignment"></div>

  <button onclick="playAudio()">Play Native Audio</button>

  <h3>Record Your Pronunciation</h3>
  <button id="startBtn">Start</button>
  <button id="stopBtn" disabled>Stop</button>
  <button id="uploadBtn" disabled>Upload</button>
  <div id="recordingIndicator" style="display: none;">Recording... <span id="recordingTimer">0.0</span>s</div>
  <div id="statusMessage"></div>

  <audio id="audioPlayer" controls style="display:none;"></audio>
  <audio id="recordedPlayer" controls style="display:none;"></audio>

  <div id="pitch-plot"></div>

  <script>
    // globals for current audio file and pitch plot data
    let currentAudio = null;
    let timeSeries = [];
    let pitchSeries = [];
    const learnerPitches = new Set();
    const statusMsg = document.getElementById("statusMessage");

    // manage recording state, chunks, and timing
    const recorder = {
      mediaRecorder: null,
      chunks: [],
      stream: null,
      startTime: null,
      interval: null
    };

    const updateButtons = ({ isRecording, hasRecording }) => {
      document.getElementById("startBtn").disabled = isRecording;
      document.getElementById("stopBtn").disabled = !isRecording;
      document.getElementById("uploadBtn").disabled = !hasRecording;
    };

    const resetRecordingUI = () => {
      document.getElementById("recordingIndicator").style.display = "none";
      document.getElementById("recordingTimer").textContent = "0.0";
      document.getElementById("recordedPlayer").style.display = "none";
      updateButtons({ isRecording: false, hasRecording: false });
    };

    // helper function to render characters and pinyin in two lines per character
    const createAlignedTextHTML = (chars, pinyin) => {
      const charList = chars.split("");
      const pinyinList = pinyin.split(" ");
      return "<div style='display: flex; gap: 10px; flex-wrap: wrap;'>" +
        charList.map((ch, i) =>
          `<div style="text-align:center;">
            <div>${ch}</div>
            <div style="font-size: 0.9em; color: gray;">${pinyinList[i] || ""}</div>
          </div>`).join("") +
        "</div>";
    };

    // get pitch and alignment data for a sentence and updates the plot and text display
    const loadFileOptions = async () => {
      const res = await fetch("/api/available");
      const files = await res.json();
      const selector = document.getElementById("fileSelector");
      selector.innerHTML = "";
      files.forEach(id => {
        const opt = document.createElement("option");
        opt.value = id;
        opt.textContent = id;
        selector.appendChild(opt);
      });
      if (files.length > 0) {
        selector.value = files[0];
        loadAndPlotFile(files[0]);
      }
    };

    const loadAndPlotFile = async (filename) => {
      const res = await fetch(`/api/pitch/${filename}`);
      if (!res.ok) return;

      const data = await res.json();
      currentAudio = data.audio;

      const { alignment, pinyin, traditional, simplified, english } = data;
      document.getElementById("english-sentence").textContent = english;

      timeSeries = [];
      pitchSeries = [];
      const annotations = [];
      const shapes = [];

      alignment.forEach(seg => {
        const { start, end, pitch_segment, text } = seg;
        const step = (end - start) / pitch_segment.length;
        pitch_segment.forEach((hz, i) => {
          timeSeries.push(start + i * step);
          pitchSeries.push(hz);
        });

        annotations.push({
          x: (start + end) / 2,
          y: Math.max(...pitchSeries) * 1.1,
          text,
          showarrow: false,
          font: { size: 16 }
        });

        shapes.push(
          { type: 'line', x0: start, x1: start, y0: 0, y1: 1, xref: 'x', yref: 'paper', line: { color: 'red', width: 1, dash: 'dot' } },
          { type: 'line', x0: end, x1: end, y0: 0, y1: 1, xref: 'x', yref: 'paper', line: { color: 'red', width: 1, dash: 'dot' } }
        );
      });

      const nativeTrace = {
        x: timeSeries,
        y: pitchSeries,
        type: "scatter",
        mode: "lines",
        line: { shape: "spline" },
        name: "Native Pitch"
      };

      const markerTrace = {
        x: [0],
        y: [0],
        mode: "markers",
        marker: { color: "blue", size: 8 },
        name: "Playback Position"
      };

      const layout = {
        title: `Pitch Contour: ${filename}`,
        xaxis: { title: "Time (s)" },
        yaxis: { title: "Pitch (Hz)", range: [0, Math.max(...pitchSeries) * 1.2] },
        annotations,
        shapes
      };

      Plotly.newPlot("pitch-plot", [nativeTrace, markerTrace], layout);

      const display = document.getElementById("scriptChoice").value;
      const output = document.getElementById("text-alignment");

      output.innerHTML = display === "pinyin" ? `<div>${pinyin}</div>` :
                         display === "traditional" ? `<div>${traditional}</div>` :
                         display === "simplified" ? `<div>${simplified}</div>` :
                         display === "both_trad" ? createAlignedTextHTML(traditional, pinyin) :
                         display === "both_simp" ? createAlignedTextHTML(simplified, pinyin) : "";

      // try plotting learner pitch if already uploaded
      if (learnerPitches.has(filename)) {
        const resp = await fetch(`/api/learner_pitch/${filename}`);
        if (resp.ok) {
          const learnerData = await resp.json();
          const lpitch = learnerData.pitch;
          const step = timeSeries[timeSeries.length - 1] / lpitch.length;
          const ltime = lpitch.map((_, i) => i * step);
          const learnerTrace = {
            x: ltime,
            y: lpitch,
            mode: "lines",
            type: "scatter",
            line: { color: "green", shape: "spline" },
            name: "Learner Pitch"
          };
          Plotly.addTraces("pitch-plot", learnerTrace);
        }
      }
    };

    document.getElementById("scriptChoice").onchange = () => {
      loadAndPlotFile(document.getElementById("fileSelector").value);
    };
    document.getElementById("fileSelector").onchange = () => {
      resetRecordingUI();
      loadAndPlotFile(document.getElementById("fileSelector").value);
    };

    const playAudio = () => {
      const audio = document.getElementById("audioPlayer");
      if (!currentAudio) return;
      audio.src = `/audio/${currentAudio}`;
      audio.play();
      audio.style.display = "block";

      const updateDot = () => {
        const t = audio.currentTime;
        const i = timeSeries.findIndex(x => x >= t);
        if (i >= 0) {
          Plotly.restyle("pitch-plot", { x: [[timeSeries[i]]], y: [[pitchSeries[i]]] }, [1]);
        }
        if (!audio.paused && !audio.ended) requestAnimationFrame(updateDot);
      };
      requestAnimationFrame(updateDot);
    };

    // start microphone recording and updates recording UI
    document.getElementById("startBtn").onclick = async () => {
      try {
        recorder.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder.mediaRecorder = new MediaRecorder(recorder.stream);
        recorder.chunks = [];

        recorder.mediaRecorder.ondataavailable = e => {
          if (e.data.size > 0) recorder.chunks.push(e.data);
        };

        recorder.mediaRecorder.onstop = () => {
          const blob = new Blob(recorder.chunks, { type: "audio/webm" });
          const url = URL.createObjectURL(blob);
          const player = document.getElementById("recordedPlayer");
          player.src = url;
          player.style.display = "block";
          updateButtons({ isRecording: false, hasRecording: true });
        };

        recorder.startTime = Date.now();
        document.getElementById("recordingIndicator").style.display = "block";
        recorder.interval = setInterval(() => {
          const elapsed = ((Date.now() - recorder.startTime) / 1000).toFixed(1);
          document.getElementById("recordingTimer").textContent = elapsed;
        }, 100);

        recorder.mediaRecorder.start();
        updateButtons({ isRecording: true });

      } catch (err) {
        statusMsg.textContent = "Microphone access denied.";
        statusMsg.style.color = "red";
      }
    };

    document.getElementById("stopBtn").onclick = () => {
      try {
        recorder.mediaRecorder.stop();
        clearInterval(recorder.interval);
        document.getElementById("recordingIndicator").style.display = "none";
      } catch (e) {
        console.warn("Stop error:", e);
      }
    };

    // upload learner recording to backend and triggers learner pitch replot
    document.getElementById("uploadBtn").onclick = async () => {
      statusMsg.textContent = "";
      const fileId = document.getElementById("fileSelector").value;
      const blob = new Blob(recorder.chunks, { type: "audio/webm" });
      const formData = new FormData();
      formData.append("audio", blob, `${fileId}_learner.webm`);

      try {
        const res = await fetch("/upload", { method: "POST", body: formData });
        if (!res.ok) throw new Error(await res.text());

        learnerPitches.add(fileId);
        statusMsg.textContent = "Upload successful!";
        statusMsg.style.color = "green";
        document.getElementById("recordedPlayer").src = `/learner_audio/${fileId}_learner.wav`;

        loadAndPlotFile(fileId);

      } catch (err) {
        statusMsg.textContent = "Upload failed: " + err.message;
        statusMsg.style.color = "red";
      }
    };

    // initialize dropdowns and load default sentence on page load  
    window.onload = () => {
      loadFileOptions();
      resetRecordingUI();
      Plotly.newPlot("pitch-plot", [], {
        title: "Pitch Contour: (waiting...)",
        xaxis: { title: "Time (s)" },
        yaxis: { title: "Pitch (Hz)", range: [0, 400] }
      });
    };
  </script>
</body>
</html>
